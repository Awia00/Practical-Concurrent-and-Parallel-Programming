# Mandatory Handin 1
awis@itu.dk
NOTE: I time results on my smartphone so unfortunately the results are not very precise.


## Exercise 2.1

### 1)
Results:
- 7.0 seconds
- 7.0 seconds
- 7.0 seconds

### 2)
See MyAtomicInteger.java for sourcecode


### 3)
Yes it is possible and I get the same result.
The new version has running time results:
- 4.1 seconds
- 4.2 seconds
- 4.3 seconds


### 4)
No since race conditions still occur. Volatile does not ensure that multiple writes at the same time happens serially equivalent.


### 5)
It is not neccesary for AtomicInteger to be final, since the object is never changed only its internal values, which in turn does not get affected by the final modifier.

As for speed I get the following results:
- 4.2 seconds
- 3.9 seconds
- 4.0 seconds

So a small speedup, but it is difficult to say when I do timings manually.

## Exercise 2.2

### 1)
It is important because OneValueCache changes throughout the lifetime of the program. Therefore it is mutable, and when we have mutable fields we need to ensure visibility between threads.
This is achieved by using the volatile modifier. 

### 2)
Final has the same properties as volatile, so in some rare cases there could be problems with visibility of the fields. Also by making them final there can never happen thread-issues so if it is not neccesary to have mutable fields, it is a good idea to make them final in any case.



## 2.3

### 1)
Increment and Get is synchronized. The counts array is final by good design.
getSpan does not need to be synchronized since it only reads a value which is never changed on the object - therefore no raceconditions or other thread-issues can happen.

### 2)
See the changes in SimpleHistogram.java

### 3)
See Histogram3 in SimpleHistogram.java

The methods do not need to be syncronized, since the values in the array are threadsafe. and since the array is also threadsafe since it is final, there is no issues which needs to be solved by the syncronized keyword

### 4)
See Histogram4 in SimpleHistogram.java


### 5)
All of the methods are implemented in a way as to provide a snapshot of the values.
Histogram2 returns a copy of the array and therefore will not see any future changes to the original histogram.
Histogram3 converts all the AtomicIntegers to ints in a new array and therefore will not either see any changes
Histogram4 puts all the values into an int array and therefore is like the copy in histogram2.


### 6)
See Histogram5 in SimpleHistogram.java


## 2.4

### 1)
See TestCache.java for implementation

### 2)
(Memoizer1)
Yes there is 115000 calls, but unfortunately i cannot see usertime and realtime. But I have timed the implementation with my phone:
    - 12.3 seconds
    - 12.3 seconds

### 3)
Calls to factorizer (Memoizer2) = 237013 so that is about double of the Memoizer1

Timing results:
    - 6.6 seconds
    - 6.4 seconds

I can hear on my machine that it is hard at work on this one: which makes sense because there is a lot more work done on all the cores.

### 4)
Calls to factorizer (Memoizer3) = 116673

time results:
    - 5.6 seconds
    - 5.7 seconds

A few more calls to factorizer due to double calculations, but overall fast (because its multithreaded) and more effective than Memoizer2 since the cache is better

### 5)
Calls to factorizer (Memoizer4) = 115000
    - 5.5 seconds
    - 5.5 seconds

The minimal amount of calls to the factorizer while having a good speedup from multithreading. But conceptually more difficult to understand

### 6)
Calls to factorizer (Memoizer5) = 115000
    - 5.6 seconds
    - 5.5 seconds

The minimal amount of calls to the factorizer while having a good speedup from multithreading.  But conceptually more difficult to understand like memoizer4.

### 7)
see TestCache.java for implementation
Calls to factorizer (Memoizer0) = 115000
    - 5.9 seconds
    - 5.9 seconds

So a bit slower than 3, 4 and 5 but still way faster and way simpler than some of the other classes.